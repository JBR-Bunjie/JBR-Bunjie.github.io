{"title":"","uid":"f73a8e23e6f6f669cf99c7dba8fa0722","slug":"Rendering/SRP/了解GPU","date":"2024-01-10T06:00:33.246Z","updated":"2024-02-16T15:17:44.087Z","comments":true,"path":"api/articles/Rendering/SRP/了解GPU.json","keywords":null,"cover":null,"content":"<h1 id=\"gpu\">GPU</h1>\r\n<blockquote>\r\n<p>让我们把一个物体的渲染过程分为两部分：一部分是应用阶段的渲染任务规划，另一部分则是GPU的片上渲染流程。</p>\r\n<p>对于GPU渲染流程，由于涉及硬件，除非主机平台的定制化优化，开发者通常无法直接干预。应用阶段则给开发者更大的可能性。国内游戏通常种类繁多，一款通用的渲染管线，通常存在冗余，不合适的设计，或者一些特殊需求难以实现，另外渲染管线占用了大量CPU的资源，是游戏优化的重要部分，所以在移动端游戏开发任务愈发复杂的情况下，开发者有更强烈的需求定制更适合自己项目的渲染管线。</p>\r\n<p>Unity中SRP则承担起这样的任务，SRP希望开发者可以以更低的学习成本来修改或者定制渲染流程。所以SRP尽可能隐藏复杂内容，如剔除，合批，物体渲染，阴影渲染，API调用等，更多的将流程问题交予开发者处理。</p>\r\n</blockquote>\r\n<h2 id=\"了解gpu基本结构\">了解GPU基本结构</h2>\r\n<blockquote>\r\n<p><strong>GPU</strong>全称是<strong>Graphics Processing\r\nUnit</strong>，图形处理单元。它的功能最初与名字一致，是专门用于绘制图像和处理图元数据的特定芯片，后来渐渐加入了其它很多功能。</p>\r\n</blockquote>\r\n<p>以最基本的图形流水线为例：</p>\r\n<figure>\r\n<img src=\"......\\images\\Rendering\\image-20240120221152143.png\"\r\nalt=\"image-20240120221152143\" />\r\n<figcaption aria-hidden=\"true\">image-20240120221152143</figcaption>\r\n</figure>\r\n<p>早期的GPU实现中，根据我们在流水线上的划分，我们会直接做VS和PS的硬件实现以提高效率。2003年的GeForce\r\nFX\r\n5600上就有两个VS和四个PS。在早期的显卡上做这种区分可行的一个原因是，早期的VS和PS负责的计算内容是不同的：</p>\r\n<ul>\r\n<li>VS主要处理坐标运算，这需要较高的精度，用到的是FP32 ALU</li>\r\n<li>PS主要处理纹理采样，这不需要较高的精度，可以采用Low Precision\r\nALU单元，但却需要额外的采样器用于采用纹理</li>\r\n</ul>\r\n<p>但是这样的设计很容易出现一方闲置的同时另一方高负载的情况：</p>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001553857-826068031.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>并且随着图形技术的发展，我们在一些时候就是需要在VS中读取纹理，在PS中需要进行高精度的运算。</p>\r\n<p>以上的种种需求使得GPU单元的设计逐渐趋于统一化，最终诞生了\r\n<code>Unified Shader Architecture</code>。在这种硬件架构中，各个单元的设计被统一，但仍然归属于流水线上的不同阶段——我们通过调度器去动态分配核心去执行流水线中的不同阶段。</p>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001601359-1264983738.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>有了这样的思路，GPU的核心设计就不再是基于完整Shader的设计，而是可以单元化：ALU、Sampler、Scheduler等器件彼此都独立出来，硬件设计者可以根据实际情况去分配各器件数量：</p>\r\n<p><img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001056361-789565826.png\"\r\nalt=\"img\" /> TU102 GPU, From <a\r\nhref=\"https://images.nvidia.com/aem-dam/en-zz/Solutions/design-visualization/technologies/turing-architecture/NVIDIA-Turing-Architecture-Whitepaper.pdf\">NVIDIA-Turing-Architecture-Whitepaper.pdf</a></p>\r\n<p><img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001113377-1820574161.png\"\r\nalt=\"img\" /> TU102中的SM单元，一个SM中有32个Unified Shader(Cuda\r\nCore)，但是只有四个Texture Sampler。</p>\r\n<p>这种Unified\r\nShader既能实现VS和PS本身的需求，也可以满足后来的更多Shader的需求：</p>\r\n<p><img src=\"......\\images\\Rendering\\image-20240215142140280.png\"\r\nalt=\"image-20240215142140280\" />\r\n现代图形流水线的大致逻辑划分，从直觉上想，各个Shader单元都应该有物理实现——这样的实现难度太大，且通用性过低</p>\r\n<h2 id=\"了解gpu与cpu的主要区别\">了解GPU与CPU的主要区别</h2>\r\n<p>相较于CPU，GPU具有天然的并行性，这主要体现为，CPU一般是SISD(Single\r\nInstruction stream, Single Data\r\nstream，单指令单数据流)，而GPU一般则是SIMD(single instruction, multiple\r\ndata)的。当然，这并不是定死的，在<a\r\nhref=\"https://www.bilibili.com/video/BV1u3411M72A/?p=3&amp;spm_id_from=pageDriver\">上帝视角看GPU（3）：部署到硬件_哔哩哔哩_bilibili</a>中，有这样一个很棒的类比：</p>\r\n<blockquote>\r\n<p>这里拿大家比较熟悉的公路来作类比：</p>\r\n<p>指令类比于红绿灯，数据类比于车，数据流类比于路面(车道)</p>\r\n<p>SISD中，一个红绿灯控制一条车道上的走向。CPU上的核心是SIMD的，并带有一些SIMD指令集作为补充，如能4宽度的SSE指令集、16宽度的AVX-512等指令集</p>\r\n<p>SIMD中，有多个车道，共享同一个红绿灯，每个车道上的走向必须一致。GPU上的核心，即为流处理器，就是指的这些车道，宽度一般为16的倍数，它们总是执行相同的指令，这一组核心成为Wrap或Wave</p>\r\n</blockquote>\r\n<p>不过，虽然SIMD的做法为GPU带来了CPU所无可企及的计算能力，但也在控制上则带来了麻烦：例如在32位宽的Wrap中，如果只有两三个计算任务，那多余的宽度就浪费了；又比如一个Wrap中的计算任务中，需要动态地根据中途的计算结果改变流程，那么则会与SIMD的形式产生冲突(比如if语句的使用导致的分支分歧，就会导致GPU中的核心执行不同的实际指令)。一般来说，前者需要在软件方面下手，用尽可能多的任务填满GPU；而后者则可能会在GPU上引入一定程度的MIMD。</p>\r\n<blockquote>\r\n<p>传统的MIMD的做法是，为每一条车道都引入一个红绿灯来保证车道独立，彼此互不相干。但是这会导致硬件的控制电路的设计复杂度过高，往往是得不偿失的。Nvidia上的做法就比较取巧：虽然仍然是每条车道都有红绿灯，但是此时的红绿灯在亮灭时，会和所有相同步骤的红绿灯一同亮灭，用时间上的消耗去消除了计算上的浪费，在实际执行顺序上应该更类似于SIMD。</p>\r\n</blockquote>\r\n<p>显存上也在一定程度上延续了这种思路：区别于插在主板上的、一般为32~64位的DDR主存，128~512位宽的显存直接焊接于显卡的PCB板上，每个颗粒都可由GPU直接、同时读取，由此为GPU带来了高吞吐量和高延迟，该延迟一般在百纳秒，比主存高很多，因此当我们从显存中读取数据时，我们收获的往往是一整批数据。此时如果GPU完全暂停执行，只是去等待数据的传输的话就会严重地影响到执行效率了。但是我们可以通过\"计算掩盖访存\"：由于Wrap的执行是受调度器控制的，先请求读取显存的Wrap会被调度器挂起，此时调度器会激活下一个Wrap并执行它的计算任务直到再次遇到读取显存的任务，当前面的Wrap再次可用时，则可以重新启动它。但是当所有Wrap都处于访存等待时，就无法通过这种\"计算掩盖访存\"的方式解决延迟问题了，需要修改算法。正因为GPU可以利用这种\"计算掩盖访存\"的方法，导致它对多级缓存的要求小很多，而CPU为了降低访存的延迟，则需要很大的芯片面积去做多级缓存。值得注意的是，每个SM都有一块内部空间叫Register\r\nFile，寄存器堆，每个Wrap都会占用一部分用于存储局部变量等，要是整个空间都占满了，那也没办法继续调度更多Wrap进来了，也只能真的停下来等待访存的结果。</p>\r\n<p>通过\"计算掩盖访存\"的方式，我们在执行时的线程数往往是能高于GPU实际的核心数的，这个CPU的超线程很像：通过调度把局部资源尽量占满，使硬件线程数高于核数</p>\r\n<p>总结：</p>\r\n<table>\r\n<thead>\r\n<tr class=\"header\">\r\n<th></th>\r\n<th>CPU</th>\r\n<th>GPU</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td><strong>延迟容忍度</strong></td>\r\n<td>低</td>\r\n<td>高</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><strong>并行目标</strong></td>\r\n<td>任务（Task）</td>\r\n<td>数据（Data）</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><strong>核心架构</strong></td>\r\n<td>多线程核心</td>\r\n<td>SIMT核心</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><strong>线程数量级</strong></td>\r\n<td>10^1 ~ 10^2</td>\r\n<td>&gt; 10^3</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><strong>吞吐量</strong></td>\r\n<td>低</td>\r\n<td>高</td>\r\n</tr>\r\n<tr class=\"even\">\r\n<td><strong>缓存需求量</strong></td>\r\n<td>高</td>\r\n<td>低</td>\r\n</tr>\r\n<tr class=\"odd\">\r\n<td><strong>线程独立性</strong></td>\r\n<td>低</td>\r\n<td>高</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<blockquote>\r\n<p>CPU就像是一辆轿车，上车就走，直奔目的地，但一趟运不了太多人</p>\r\n<p>GPU则像是一辆公交，每站都停，还得花很多时间上人，但载客量大</p>\r\n</blockquote>\r\n<h2 id=\"了解gpu的内存结构\">了解GPU的内存结构</h2>\r\n<p>根据CPU和GPU是否共享内存，可分为两种类型的CPU-GPU架构：</p>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001850363-356121869.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>上图左是<strong>分离式架构</strong>，CPU和GPU各自有独立的缓存和内存，它们通过PCI-e等总线通讯。这种结构的缺点在于\r\nPCI-e\r\n相对于两者具有低带宽和高延迟，数据的传输成了其中的性能瓶颈。目前使用非常广泛，如PC、智能手机等。</p>\r\n<p>上图右是<strong>耦合式架构</strong>，CPU 和 GPU 共享内存和缓存。AMD\r\n的 APU 采用的就是这种结构，目前主要使用在游戏主机中，如 PS4。</p>\r\n<p>在存储管理方面，分离式结构中 CPU 和 GPU\r\n各自拥有独立的内存，两者共享一套虚拟地址空间，必要时会进行内存拷贝。对于耦合式结构，GPU\r\n没有独立的内存，与 GPU 共享系统内存，由 MMU 进行存储管理。</p>\r\n<ul>\r\n<li>寄存器和本地内存为<strong>每一个线程私有</strong></li>\r\n<li>共享内存为每一个<strong>线程块</strong>中的<strong>所有线程共享</strong></li>\r\n<li>全局内存、常量内存、纹理内存被<strong>GPU设备上的所有线程共享</strong></li>\r\n</ul>\r\n<h3 id=\"寄存器register\">1.寄存器(register)</h3>\r\n<p>寄存器是在片上（on\r\nchip）的存储结构，用来存储一些线程的暂存数据。它是GPU上读写最快的存储结构，变量一般都放在寄存器中。</p>\r\n<p>同时，寄存器变量是<strong>每个线程私有的</strong>，<strong>生命周期与跟线程相同</strong>。它能接受线程的直接访问，并随着线程释放而释放。但是它的容量较小是稀有资源。以目前最新的Ampere架构的GA102为例，每个SM上的寄存器总量256KB，使用时被均分为了4块，且该寄存器块的64KB空间需要被warp中线程平均分配，所以在线程多的情况下，每个线程拿到的寄存器空间相当小。在编写代码时，让核函数使用更少的寄存器，这样每个SM能容纳更多Block，提高并行能力。</p>\r\n<p>寄存器的分配对SM的占用率（occupancy）存在影响，可以通过<a\r\nhref=\"https://link.zhihu.com/?target=https%3A//xmartlabs.github.io/cuda-calculator/\">CUDA\r\nOccupancy Calculator</a>\r\n计算比较，举例：如图当registers从32增加到128时，occupancy从100%降低到了33.33%：</p>\r\n<figure>\r\n<img\r\nsrc=\"https://pic1.zhimg.com/80/v2-95a35f3f4a0b93ba7fafa93757a47338_720w.webp\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>如果寄存器放不下，那会放到本地内存上，即所谓的register\r\nspilling（寄存溢出）。</p>\r\n<h3 id=\"局部内存local-memory\">2.局部内存(local memory)</h3>\r\n<p>局部内存(local memory)\r\n是线程私有的内存资源，线程之间不可以相互访问，但硬件位置则是off\r\nchip的状态，所以访问速度跟全局内存一样。局部内存主要是用来解决当<strong>寄存器不足</strong>时的场景，即在线程申请的变量超过可用的寄存器大小时，nvcc(GPU程序的编译器)会自动将一部数据放置到片下内存里面。</p>\r\n<p>注意，局部内存设置的过程是在编译阶段就会确定。</p>\r\n<p>此外，还有几种情况，也会把变量放置在本地内存上：</p>\r\n<ul>\r\n<li>编译期无法确定值的数组</li>\r\n<li>占用较多内存的变量</li>\r\n</ul>\r\n<h3 id=\"共享内存shared-memory\">3.共享内存（shared memory)</h3>\r\n<p>共享内存是<strong>由一个线程块中的所有线程共享的，</strong>生命周期伴随整个Block，随着Block执行完成而释放。存储硬件位于芯片上（on\r\nchip），访问速度较快。</p>\r\n<p>共享内存主要是缓存一些需要反复读写的数据，由**__shared__修饰符**修饰的变量放在共享内存中。共享内存与L1的位置、速度极其类似，但是它们在控制与生命周期的管理各不相同，共享内存的使用受用户控制，L1受系统控制</p>\r\n<p>共享内存常用于块内线程通信，同一个block中的thread通过共享内存来通信。</p>\r\n<h3 id=\"常量内存constant-memory\">4.常量内存(constant memory)</h3>\r\n<p>常量内存(constant memory)\r\n是存储在<strong>片下</strong>存储的设备内存上，对设备中的<strong>所有线程可见</strong>，能通过特殊的常量内存缓存（constant\r\ncache）进行缓存读取的只读内存。</p>\r\n<p>常量内存(constant\r\nmemory)是为解决一个warp内多线程的<strong>访问相同数据</strong>的速度太慢而设立的，如下图所示：</p>\r\n<figure>\r\n<img\r\nsrc=\"https://pic1.zhimg.com/80/v2-186827a64857f89df6860cd874fa1da8_720w.webp\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>所有运算的thread都需要访问一个constant_A的常量，在存储介质上面constant_A的数据只保存了一份，而内存的物理读取方式决定了这么多thread不能在同一时刻读取到该变量，所以会出现先后访问的问题，<strong>这样使得并行计算的thread出现了运算时差。</strong>常量内存正是解决这样的问题而设置的，它有对应的cache位置产生多个副本，让thread访问时不存在冲突，从而提高并行度。</p>\r\n<p>需要说明的是，在硬件上面，constant单元也分了多级（L1/L1.5/L2），而且存在线程访问延时，比如上述例子中的广播操作，当线程数量增加时延时也会随之增加。</p>\r\n<figure>\r\n<img\r\nsrc=\"https://pic3.zhimg.com/80/v2-faaa34cea150d6596947c040f08eb5fa_720w.webp\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<h3 id=\"纹理内存texture-memory\">5.纹理内存（texture memory）</h3>\r\n<p>纹理（texture\r\nmemory）是一种针对图形化数据的专用内存，对设备中的<strong>所有线程可见</strong>。每一个<strong>SM</strong>中都配备着专用的texture\r\ncache（per-SM）。现在，这里的texture应该理解为类似于1D、2D、3D纹理那样的数据结构，其相邻数据之间存在一定关系，或者相邻数据之间需要进行相同或类似的运算。</p>\r\n<p>texture内存的构成包含 global + cache +\r\n处理单元，texture为只读内存。texture的优势：</p>\r\n<ul>\r\n<li>texture memory 进行图像类数据加载时，\r\nwarp内的thread访问的数据地址相邻，从而减少带宽的浪费。</li>\r\n<li>texture\r\n在运算之前能进行一些处理（或者说它本身就是运算），比如聚合、映射等。</li>\r\n</ul>\r\n<p>SM内的Tex的速度很快，进行数据拿取（fetch）的时候，能够在一个clock时钟内完成对数据的一些预处理。</p>\r\n<p>需要注意的是，</p>\r\n<h3 id=\"全局内存global-memory\">6.全局内存(global memory)</h3>\r\n<p>全局内存(global memory)为片下（off\r\nchip）内存，能被设备内的所有线程访问、全局共享。<code>__device__</code>修饰符表明是全局变量。比如<strong>cudaMalloc分配的就是全局内存</strong>！。</p>\r\n<p>跟CPU架构一样，运算单元不能直接的使用全局内存的数据，需要经过缓存，其过程如下图所示：</p>\r\n<figure>\r\n<img\r\nsrc=\"https://pic2.zhimg.com/80/v2-c92d49a047bdb41fceddd68a34f1ff15_720w.webp\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<h3 id=\"cache\">7.Cache</h3>\r\n<p>GPU有着和CPU类似的缓存机制，并且都是不可编程、由硬件自动实现的缓存机制，这些缓存之中共有四种类别：</p>\r\n<ul>\r\n<li>L1 cache（per-SM）</li>\r\n<li>L2 cache（per-device）</li>\r\n<li>只读的constant cache（per-SM）</li>\r\n<li>只读的texture cache（per-SM）</li>\r\n</ul>\r\n<p>每个SM都配置着L1 cache，一个只读constant cache和texture\r\ncache来提升性能。同时所有SM共享一个L2 cache。</p>\r\n<p>L1 cache 和 L2 cache 都是用来缓存 local 和 global memory 的。CUDA11\r\nA100 上的 L2 能够设置至多 40MB 的持续化数据(persistent\r\ndata)，为所有SM都能访问到，速度比全局内存块，所以为了提高速度有些小的数据可以缓存到\r\nL2 上面；L1 用于存储 SM 内的数据，SM 内的运算单元能够共享，但跨 SM\r\n之间的 L1 不能相互访问。</p>\r\n<p>需要注意的是，在CPU方面，memory的load/store都会被cache。但是在GPU上，只有load操作会被cache，store则不会。</p>\r\n<p>TextureCache是GPU纹理的缓存硬件，当Core执行着色器程序访问纹理像素时，会先确定在TextureCache这一硬件结构中是否命中，如果命中这从TextureCache进行获取，这一过程通常会在几十个时钟周期内完成。如果未命中，则会请求TextureMemory进行获取，但是这一操作会涉及上百个时钟周期。Tex是纹理内存访问的另一重要硬件结构，在一个SM结构中一个Core或多个Core会对应一个Tex，也就是一个纹理访问窗口，Tex在向TextureMemory请求数据时会执行硬件的解压缩操作，且在纹理采样时TexUnit则可根据参数设置进行采样以及过滤。</p>\r\n<p>ConstantCache用来缓冲ConstantMemory数据，ConstCache有一定内存限制，Unity单个ContantBuffer内存占用在64KB以下，Unity\r\nInstance由于使用了ConstantBuffer所以绘制数量会受到限制。另外在定义Shader的Uniform变量时，需要注意到内存对齐，在OpenGL\r\nstd140标准，ConstantBuffer是128位对齐的也就是4个float值，所以对于下面两种情况，第一段实际占用12\r\nfloat空间，而第二个只会占用8个float空间。</p>\r\n<pre class=\"line-numbers language-glsl\" data-language=\"glsl\"><code class=\"language-glsl\">CBUFFER_START(UnityPerMaterial)\nfloat2 a;\nfloat4 b;\nfloat2 c;\nCBUFFER_END\n\nCBUFFER_START(UnityPerMaterial)\nfloat4 b;\nfloat2 a;\nfloat2 c;\nCBUFFER_END</code></pre>\r\n<p>小结各个存储结构的生命周期、作用域、限定符：</p>\r\n<p><img\r\nsrc=\"https://pic2.zhimg.com/80/v2-f7c057e07b3b9c2709fcb09342478ba5_720w.webp\"\r\nalt=\"img\" />\r\n<code>float var[100]</code>就是因为寄存器放不下，进而放在本地内存。</p>\r\n<p>各个部件的存取速度从寄存器到系统内存依次变慢：</p>\r\n<table>\r\n<colgroup>\r\n<col style=\"width: 14%\" />\r\n<col style=\"width: 10%\" />\r\n<col style=\"width: 14%\" />\r\n<col style=\"width: 10%\" />\r\n<col style=\"width: 10%\" />\r\n<col style=\"width: 25%\" />\r\n<col style=\"width: 14%\" />\r\n</colgroup>\r\n<thead>\r\n<tr class=\"header\">\r\n<th>存储类型</th>\r\n<th>寄存器</th>\r\n<th>共享内存</th>\r\n<th>L1缓存</th>\r\n<th>L2缓存</th>\r\n<th>纹理、常量缓存</th>\r\n<th>全局内存</th>\r\n</tr>\r\n</thead>\r\n<tbody>\r\n<tr class=\"odd\">\r\n<td>访问周期</td>\r\n<td>1</td>\r\n<td>1~32</td>\r\n<td>1~32</td>\r\n<td>32~64</td>\r\n<td>400~600</td>\r\n<td>400~600</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n<h2\r\nid=\"从渲染过程看gpu各部件的执行顺序\">从渲染过程看GPU各部件的执行顺序</h2>\r\n<p>具体的GPU受调用过程是很复杂的，并且绝大多数内容对游戏程序员是完全透明的，这很好理解——毕竟这就是我们的计算机。但是理解一些总是好的：<a\r\nhref=\"https://www.bilibili.com/video/BV1QT4y1r7Vq\">上帝视角看GPU（4）：完整的软件栈_哔哩哔哩_bilibili</a></p>\r\n<p>还是从DrawCall开始吧，其执行顺序都大体如下：</p>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001159387-965011107.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>这是从Fermi开始NVIDIA使用类似的原理架构：使用一个Giga Thread\r\nEngine来管理所有正在进行的工作，GPU被划分成多个GPCs(Graphics Processing\r\nCluster)，每个GPC拥有多个SM（SMX、SMM）和一个光栅化引擎(Raster\r\nEngine)，它们其中有很多的连接，最显著的是Crossbar，它可以连接GPCs和其它功能性模块（例如ROP或其他子系统）。</p>\r\n<h3 id=\"sm\">SM</h3>\r\n<p>程序员编写的shader是在SM上完成的。每个SM包含许多为线程执行数学运算的Core（核心）。例如，一个线程可以是顶点或像素着色器调用。这些Core和其它单元由Warp\r\nScheduler驱动，Warp\r\nScheduler管理一组32个线程作为Warp（线程束）并将要执行的指令移交给Dispatch\r\nUnits。</p>\r\n<p>GPU中实际有多少这些单元（每个GPC有多少个SM，多少个GPC\r\n......）取决于芯片配置本身。例如，GM204有4个GPC，每个GPC有4个SM，但Tegra\r\nX1有1个GPC和2个SM，它们均采用Maxwell设计。SM设计本身（内核数量，指令单位，调度程序......）也随着时间的推移而发生变化，并帮助使芯片变得如此高效，可以从高端台式机扩展到笔记本电脑移动。</p>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001212393-1848942244.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>如上图，对于某些GPU（如Fermi部分型号）的单个SM，包含：</p>\r\n<ul>\r\n<li>32个运算核心 （Core，也叫流处理器Stream Processor）</li>\r\n<li>16个LD/ST（load/store）模块来加载和存储数据</li>\r\n<li>4个SFU（Special function\r\nunits）执行特殊数学运算（sin、cos、log等）</li>\r\n<li>128KB寄存器（Register File）</li>\r\n<li>64KB L1缓存</li>\r\n<li>全局内存缓存（Uniform Cache）</li>\r\n<li>纹理读取单元</li>\r\n<li>纹理缓存（Texture Cache）</li>\r\n<li>PolyMorph Engine：多边形引擎负责属性装配（attribute\r\nSetup）、顶点拉取(VertexFetch)、曲面细分、栅格化（这个模块可以理解专门处理顶点相关的东西）。</li>\r\n<li>2个Warp\r\nSchedulers：这个模块负责warp调度，一个warp由32个线程组成，warp调度器的指令通过Dispatch\r\nUnits送到Core执行。</li>\r\n<li>指令缓存（Instruction Cache）</li>\r\n<li>内部链接网络（Interconnect Network）</li>\r\n</ul>\r\n<h3 id=\"gpu逻辑管线\">GPU逻辑管线</h3>\r\n<p>了解上一节的部件和概念之后，可以深入阐述GPU的渲染过程和步骤。下面将以Fermi家族的SM为例，进行逻辑管线的详细说明。</p>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001228274-379363267.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<ol type=\"1\">\r\n<li>程序通过图形API(DX、GL、WEBGL)发出drawcall指令，指令会被推送到驱动程序，驱动会检查指令的合法性，然后会把指令放到GPU可以读取的Pushbuffer中。</li>\r\n<li>经过一段时间或者显式调用flush指令后，驱动程序把Pushbuffer的内容发送给GPU，GPU通过主机接口（Host\r\nInterface）接受这些命令，并通过前端（Front End）处理这些命令。</li>\r\n<li>在图元分配器(Primitive\r\nDistributor)中开始工作分配，处理indexbuffer中的顶点产生三角形分成批次(batches)，然后发送给多个GPCs。这一步的理解就是提交上来n个三角形，分配给这几个GPCs同时处理。</li>\r\n</ol>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906000842367-1857714844.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<ol start=\"4\" type=\"1\">\r\n<li>在GPC中，每个SM中的 <code>Poly Morph Engine</code>\r\n负责通过三角形索引(triangle indices)取出三角形的数据(vertex\r\ndata)，即图中的Vertex Fetch模块。</li>\r\n<li>在获取数据之后，在SM中以32个线程为一组的线程束(Warp)来调度，来开始处理顶点数据。Warp是典型的单指令多线程（SIMT，SIMD单指令多数据的升级）的实现，也就是32个线程同时执行的指令是一模一样的，只是线程数据不一样，这样的好处就是一个warp只需要一个套逻辑对指令进行解码和执行就可以了，芯片可以做的更小更快，之所以可以这么做是由于GPU需要处理的任务是天然并行的。</li>\r\n<li>SM的warp调度器会按照顺序分发指令给整个warp，单个warp中的线程会锁步(lock-step)执行各自的指令，如果线程碰到不激活执行的情况也会被遮掩(be\r\nmasked\r\nout)。被遮掩的原因有很多，例如当前的指令是if(true)的分支，但是当前线程的数据的条件是false，或者循环的次数不一样（比如for循环次数n不是常量，或被break提前终止了但是别的还在走），因此在shader中的分支会显著增加时间消耗，在一个warp中的分支除非32个线程都走到if或者else里面，否则相当于所有的分支都走了一遍，线程不能独立执行指令而是以warp为单位，而这些warp之间才是独立的。</li>\r\n<li>warp中的指令可以被一次完成，也可能经过多次调度，例如通常SM中的LD/ST(加载存取)单元数量明显少于基础数学操作单元。</li>\r\n<li>由于某些指令比其他指令需要更长的时间才能完成，特别是内存加载，warp调度器可能会简单地切换到另一个没有内存等待的warp，这是GPU如何克服内存读取延迟的关键，只是简单地切换活动线程组。为了使这种切换非常快，调度器管理的所有warp在寄存器文件中都有自己的寄存器。这里就会有个矛盾产生，shader需要越多的寄存器，就会给warp留下越少的空间，就会产生越少的warp，这时候在碰到内存延迟的时候就会只是等待，而没有可以运行的warp可以切换。</li>\r\n</ol>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001241355-608845528.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<ol start=\"9\" type=\"1\">\r\n<li>一旦warp完成了vertex-shader的所有指令，运算结果会被Viewport\r\nTransform模块处理，三角形会被裁剪然后准备栅格化，GPU会使用L1和L2缓存来进行vertex-shader和pixel-shader的数据通信。</li>\r\n</ol>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001250059-1971914812.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<ol start=\"10\" type=\"1\">\r\n<li>接下来这些三角形将被分割，再分配给多个GPC，三角形的范围决定着它将被分配到哪个光栅引擎(raster\r\nengines)，每个raster\r\nengines覆盖了多个屏幕上的tile，这等于把三角形的渲染分配到多个tile上面。也就是像素阶段就把按三角形划分变成了按显示的像素划分了。</li>\r\n</ol>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001300961-1313843419.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<ol start=\"11\" type=\"1\">\r\n<li>SM上的Attribute\r\nSetup保证了从vertex-shader来的数据经过插值后是pixel-shade是可读的。</li>\r\n<li>GPC上的光栅引擎(raster\r\nengines)在它接收到的三角形上工作，来负责这些这些三角形的像素信息的生成（同时会处理裁剪Clipping、背面剔除和Early-Z剔除）。</li>\r\n<li>32个像素线程将被分成一组，或者说8个2x2的像素块，这是在像素着色器上面的最小工作单元，在这个像素线程内，如果没有被三角形覆盖就会被遮掩，SM中的warp调度器会管理像素着色器的任务。</li>\r\n<li>接下来的阶段就和vertex-shader中的逻辑步骤完全一样，但是变成了在像素着色器线程中执行。\r\n由于不耗费任何性能可以获取一个像素内的值，导致锁步执行非常便利，所有的线程可以保证所有的指令可以在同一点。</li>\r\n</ol>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001313351-1662028341.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<ol start=\"15\" type=\"1\">\r\n<li>最后一步，现在像素着色器已经完成了颜色的计算还有深度值的计算，在这个点上，我们必须考虑三角形的原始api顺序，然后才将数据移交给ROP(render\r\noutput\r\nunit，渲染输入单元)，一个ROP内部有很多ROP单元，在ROP单元中处理深度测试，和framebuffer的混合，深度和颜色的设置必须是原子操作，否则两个不同的三角形在同一个像素点就会有冲突和错误。</li>\r\n</ol>\r\n<h2 id=\"光线追踪管线\">光线追踪管线</h2>\r\n<h2 id=\"移动端\">移动端</h2>\r\n<h3 id=\"带宽\">带宽</h3>\r\n<p>带宽，带宽不仅会影响计算时间，还会直接导致功耗提高——手机发烫会持久性地影响玩家的游戏体验。</p>\r\n<p>而同时，对于带宽影响最大的通常就是纹理</p>\r\n<blockquote>\r\n<p>从下面这几张图可以很好的理解纹理影响带宽的方式：</p>\r\n<figure>\r\n<img\r\nsrc=\"https://pic3.zhimg.com/80/v2-79dcc220c541103f9264cbc6284317e6_1440w.webp\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>每一个色块大小为16*16，颜色代表SM的ID，图中有32个色阶，也就是GPU存在32个SM</p>\r\n<figure>\r\n<img\r\nsrc=\"https://pic2.zhimg.com/80/v2-ed07aecd69b2f69c7d6df14b340f99ad_1440w.webp\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>每一个色块为4*8，颜色代表SM中的WarpID，同样有32个色阶，说明单个SM最多有32个warp</p>\r\n<figure>\r\n<img\r\nsrc=\"https://pic3.zhimg.com/80/v2-43fa588015f86c606df7057802056c9a_1440w.webp\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>每个色块为1*1，颜色为warp内的线程ID，依然是32个色阶，说明一个warp内有32个线程</p>\r\n<p>上图都是基于IMR GPU架构的渲染结果，移动端通常是TBR、TBDR\r\nGPU架构,但是TBR每个渲染块通常也是16*16的导致调度块可能和IMR会比较相似。TBR相关内容也比较有意思，感兴趣可以再去查看一些资料，对于TBR，TBR的设计相比于IMR会有更多可能性，尤其在对于同一个tile块中，由于可以拿到一批绘制的所有在此块中不透明三角面，所以TBR架构更有可能在硬件层面解决OverDraw的问题。</p>\r\n<p>由图1开始，我们可以看到渲染单个三角形会以16*16的块为单位调度SM，每个SM会有多个块需要执行，这里的16*16我们的可以理解为是一个block，一个block会存在多个warp，图2可以看出16*16的block内分成了4*2个warp，每个warp为执行4*8\r\n32个像素。图3有可以看出来一个warp内有32个线程，每个线程都会处理一个像素。</p>\r\n<p>那么再理一下一个三角形是如何进行像素着色：</p>\r\n<ol type=\"1\">\r\n<li>三角形光栅化后会将光栅化结果分成多个16*16的block（图1），调度GPU上SM执行Block的着色。</li>\r\n<li>当一个SM拿到16*16的block时，block内会分成4*2个Warp（图2）然后使用WarpScheduler硬件调度Warp执行。</li>\r\n<li>当SM开始执行一个Warp，使用DispatchUnit调度线程执行着色程序。</li>\r\n</ol>\r\n</blockquote>\r\n<h4 id=\"采样到底发生了什么\">采样到底发生了什么</h4>\r\n<p><strong>纹理在片下存储TextureMemory中是以tile的方式存储的，由此来增强纹理存储的局部性</strong>，每一个tile占用1个或多个CacheLine的空间也就是n\r\n*（64或128字节），这样的存储方式，在向TextureMemory请求纹理时，可以快速请求到一块纹理数据，而提高采样命中率。另外纹理压缩是以块的方式压缩的，对于\r\n<code>Astc</code>\r\n的格式，Astc存在12X12，8X8，6X6，5X5...多种压缩状态，对于一个n *\r\nn的像素块，固定存储量是16字节，那么对于64字节的CacheLine可以容纳4个压缩块。那么在每次纹理请求时TextureMemory到Cache的传送量，针对不同压缩格是不同的。所以选择合适压缩格式一定程度上可以减少带宽。</p>\r\n<p>纹理在片上cache中，L1的TextureCache通常只会有几十KB，但是一张图片在TextureMemory中是压缩状态，但是读取到Cache是则是非压缩状态，这就导致纹理块在cache中是比较大的。那么在渲染一个物体的过程中，TextureCache内的纹理块并不会存储很长时间，很快会被切换出去。所以<strong>我们希望SM在一批像素的处理中尽可能少地从TextureMemory读取纹理块</strong>。这里一批也就是是一个Block。由于在同一个SM上渲染的不同的block的通常是不连续的，不同的Block对应的采样的纹理区域差别会比较大，所以命中通常是在单个block内分析的。</p>\r\n<p>这样在着色器在渲染一个Block的过程中，假设block内的一个warp（4*8像素块）的所有线程向TexUnit请求纹理数据，我们可以知道这些请求的UV会映射在纹理的一块区域内，所以<strong>一定程度上我们可以预估这个Warp采样使用的纹理范围的大概矩形区域</strong>，来判断Texmory的请求次数。如果希望Warp每个线程命中率近可能的高，那么最优情况，在渲染这个warp所属的block的过程中，第一次未命中时，向L2Cache或者TextureMemory请求纹理块时，该纹理块包含了block渲染需要的所有纹理数据，在16*16\r\n256次的采样只有一次未命中，命中率会达到99以上。到这里再回想一下TBR架构设计也是这样，在对ColorBuffer，DepthStencilBuffer进行读写时会保证block的绘制只访问一次Tile块，所以命中率会非常高，从而极大减少与系统内存的交互，而减少功耗。</p>\r\n<h2 id=\"最后的显示输出\">最后的显示输出</h2>\r\n<h3 id=\"水平和垂直同步信号\">水平和垂直同步信号</h3>\r\n<p>在早期的CRT显示器，电子枪从上到下逐行扫描，扫描完成后显示器就呈现一帧画面。然后电子枪回到初始位置进行下一次扫描。为了同步显示器的显示过程和系统的视频控制器，显示器会用硬件时钟产生一系列的定时信号。</p>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001937801-1437499549.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>当电子枪换行进行扫描时，显示器会发出一个水平同步信号（horizonal\r\nsynchronization），简称 <strong>HSync</strong></p>\r\n<p>当一帧画面绘制完成后，电子枪回复到原位，准备画下一帧前，显示器会发出一个垂直同步信号（vertical\r\nsynchronization），简称 <strong>VSync</strong>。</p>\r\n<p>显示器通常以固定频率进行刷新，这个刷新率就是 VSync\r\n信号产生的频率。虽然现在的显示器基本都是液晶显示屏了，但其原理基本一致。</p>\r\n<p>CPU将计算好显示内容提交至 GPU，GPU\r\n渲染完成后将渲染结果存入帧缓冲区，视频控制器会按照 VSync\r\n信号逐帧读取帧缓冲区的数据，经过数据转换后最终由显示器进行显示。</p>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001947961-1190125231.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<h3 id=\"双缓冲\">双缓冲</h3>\r\n<p>在单缓冲下，帧缓冲区的读取和刷新都都会有比较大的效率问题，经常会出现相互等待的情况，导致帧率下降。</p>\r\n<p>为了解决效率问题，GPU 通常会引入两个缓冲区，即\r\n<strong>双缓冲机制</strong>。在这种情况下，GPU\r\n会预先渲染一帧放入一个缓冲区中，用于视频控制器的读取。当下一帧渲染完毕后，GPU\r\n会直接把视频控制器的指针指向第二个缓冲器。</p>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001957832-296063271.png\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<h3 id=\"垂直同步\">垂直同步</h3>\r\n<p>双缓冲虽然能解决效率问题，但会引入一个新的问题。当视频控制器还未读取完成时，即屏幕内容刚显示一半时，GPU\r\n将新的一帧内容提交到帧缓冲区并把两个缓冲区进行交换后，视频控制器就会把新的一帧数据的下半段显示到屏幕上，造成画面撕裂现象：</p>\r\n<figure>\r\n<img\r\nsrc=\"https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906002006570-2008054292.jpg\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>为了解决这个问题，GPU\r\n通常有一个机制叫做<strong>垂直同步</strong>（简写也是V-Sync），当开启垂直同步后，GPU\r\n会等待显示器的 VSync\r\n信号发出后，才进行新的一帧渲染和缓冲区更新。这样能解决画面撕裂现象，也增加了画面流畅度，但需要消费更多的计算资源，也会带来部分延迟。</p>\r\n<h2 id=\"references\">References</h2>\r\n<ul>\r\n<li><a\r\nhref=\"https://zhuanlan.zhihu.com/p/629678819\">URP代码结构以及GPU架构（万字长文）\r\n- 知乎 (zhihu.com)</a></li>\r\n<li><a\r\nhref=\"https://www.bilibili.com/video/BV1P44y1V7bu/?vd_source=c8eda79dd90c30ff02e09fb39906ac54\">上帝视角看GPU（1）：图形流水线基础_哔哩哔哩_bilibili</a></li>\r\n<li><a\r\nhref=\"https://zhuanlan.zhihu.com/p/357112957\">深入GPU硬件架构及运行机制\r\n- 知乎 (zhihu.com)</a></li>\r\n<li><a\r\nhref=\"https://zhuanlan.zhihu.com/p/463052196\">cuda编程笔记（四）：存储系统结构\r\n- 知乎 (zhihu.com)</a></li>\r\n<li><a\r\nhref=\"https://zhuanlan.zhihu.com/p/462191421\">GPU内存(显存)的理解与基本使用\r\n- 知乎 (zhihu.com)</a></li>\r\n<li><a\r\nhref=\"https://zhuanlan.zhihu.com/p/404711038\">移动端GPU架构学习笔记 +\r\n关于移动端和MRT在消耗带宽上的设计这档子事 - 知乎 (zhihu.com)</a></li>\r\n<li></li>\r\n</ul>\r\n","text":"GPU 让我们把一个物体的渲染过程分为两部分：一部分是应用阶段的渲染任务规划，另一部分则是GPU的片上渲染流程。 对于GPU渲染流程，由于涉及硬件，除非主机平台的定制化优化，开发者通常无法直接干预。应用阶段则给开发者更大的可能性。国内游戏通常种类繁多，一款通用的渲染管线，通常存在...","link":"","photos":[],"count_time":{"symbolsCount":"13k","symbolsTime":"12 mins."},"categories":[],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#gpu\"><span class=\"toc-text\">GPU</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BA%86%E8%A7%A3gpu%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">了解GPU基本结构</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BA%86%E8%A7%A3gpu%E4%B8%8Ecpu%E7%9A%84%E4%B8%BB%E8%A6%81%E5%8C%BA%E5%88%AB\"><span class=\"toc-text\">了解GPU与CPU的主要区别</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BA%86%E8%A7%A3gpu%E7%9A%84%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">了解GPU的内存结构</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%AF%84%E5%AD%98%E5%99%A8register\"><span class=\"toc-text\">1.寄存器(register)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%B1%80%E9%83%A8%E5%86%85%E5%AD%98local-memory\"><span class=\"toc-text\">2.局部内存(local memory)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98shared-memory\"><span class=\"toc-text\">3.共享内存（shared memory)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%B8%B8%E9%87%8F%E5%86%85%E5%AD%98constant-memory\"><span class=\"toc-text\">4.常量内存(constant memory)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BA%B9%E7%90%86%E5%86%85%E5%AD%98texture-memory\"><span class=\"toc-text\">5.纹理内存（texture memory）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%85%A8%E5%B1%80%E5%86%85%E5%AD%98global-memory\"><span class=\"toc-text\">6.全局内存(global memory)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#cache\"><span class=\"toc-text\">7.Cache</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BB%8E%E6%B8%B2%E6%9F%93%E8%BF%87%E7%A8%8B%E7%9C%8Bgpu%E5%90%84%E9%83%A8%E4%BB%B6%E7%9A%84%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F\"><span class=\"toc-text\">从渲染过程看GPU各部件的执行顺序</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#sm\"><span class=\"toc-text\">SM</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#gpu%E9%80%BB%E8%BE%91%E7%AE%A1%E7%BA%BF\"><span class=\"toc-text\">GPU逻辑管线</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA%E7%AE%A1%E7%BA%BF\"><span class=\"toc-text\">光线追踪管线</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%A7%BB%E5%8A%A8%E7%AB%AF\"><span class=\"toc-text\">移动端</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%B8%A6%E5%AE%BD\"><span class=\"toc-text\">带宽</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E9%87%87%E6%A0%B7%E5%88%B0%E5%BA%95%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88\"><span class=\"toc-text\">采样到底发生了什么</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%9C%80%E5%90%8E%E7%9A%84%E6%98%BE%E7%A4%BA%E8%BE%93%E5%87%BA\"><span class=\"toc-text\">最后的显示输出</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%B0%B4%E5%B9%B3%E5%92%8C%E5%9E%82%E7%9B%B4%E5%90%8C%E6%AD%A5%E4%BF%A1%E5%8F%B7\"><span class=\"toc-text\">水平和垂直同步信号</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8F%8C%E7%BC%93%E5%86%B2\"><span class=\"toc-text\">双缓冲</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9E%82%E7%9B%B4%E5%90%8C%E6%AD%A5\"><span class=\"toc-text\">垂直同步</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#references\"><span class=\"toc-text\">References</span></a></li></ol></li></ol>","author":{"name":"JBR_Bunjie","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/90251718?v=4","link":"/","description":"仿生程序员会在光环上遇见AI乐正绫吗？","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-fill.svg","link":"https://space.bilibili.com/415377461"},"github":{"icon":"/svg/social_github.svg","link":"https://github.com/JBR-Bunjie"}}}},"mapped":true,"prev_post":{"title":"速通SVN","uid":"cda6b3a504064f1ce2862973c6967299","slug":"Deploy/SVN","date":"2024-02-24T14:18:48.000Z","updated":"2024-02-25T14:52:21.237Z","comments":true,"path":"api/articles/Deploy/SVN.json","keywords":null,"cover":"https://raw.githubusercontent.com/JBR-Bunjie/JBR-Bunjie/main/back.jpg","text":"速通SVN SVN服务器 采用在线的SVN服务商 SVN也有很多代码托管平台，如 SVNBucket.com 等。大可以直接采用这种服务商来部署 SVN 服务器 自行部署SVN服务 在普通的云服务器上，我们也可以部署SVN。此时可以利用 VisualSVN server 等现有的...","link":"","photos":[],"count_time":{"symbolsCount":"5.1k","symbolsTime":"5 mins."},"categories":[{"name":"SVN","slug":"SVN","count":1,"path":"api/categories/SVN.json"},{"name":"Unity","slug":"SVN/Unity","count":1,"path":"api/categories/SVN/Unity.json"}],"tags":[{"name":"Unity","slug":"Unity","count":22,"path":"api/tags/Unity.json"},{"name":"SVN","slug":"SVN","count":1,"path":"api/tags/SVN.json"}],"author":{"name":"JBR_Bunjie","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/90251718?v=4","link":"/","description":"仿生程序员会在光环上遇见AI乐正绫吗？","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-fill.svg","link":"https://space.bilibili.com/415377461"},"github":{"icon":"/svg/social_github.svg","link":"https://github.com/JBR-Bunjie"}}}}},"next_post":{"title":"","uid":"f73a8e23e6f6f669cf99c7dba8fa0722","slug":"Dev/更好的动画效果","date":"2023-12-13T16:44:15.473Z","updated":"2023-12-21T10:30:23.701Z","comments":true,"path":"api/articles/Dev/更好的动画效果.json","keywords":null,"cover":null,"text":"一个低成本的3D效果 3D 穿梭效果？使用 UWP 也能搞定 - dino.c - 博客园 (cnblogs.com) 3D 穿梭效果？使用 CSS 轻松搞定 - ChokCoco - 博客园 (cnblogs.com) perspective - CSS: Cascading ...","link":"","photos":[],"count_time":{"symbolsCount":184,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"JBR_Bunjie","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/90251718?v=4","link":"/","description":"仿生程序员会在光环上遇见AI乐正绫吗？","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-fill.svg","link":"https://space.bilibili.com/415377461"},"github":{"icon":"/svg/social_github.svg","link":"https://github.com/JBR-Bunjie"}}}}}}