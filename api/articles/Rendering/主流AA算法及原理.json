{"title":"主流 Anti-Aliasing 算法及原理概览","uid":"bbf9542302ac0838c1965dd8fababb22","slug":"Rendering/主流AA算法及原理","date":"2023-02-25T04:23:23.000Z","updated":"2023-11-03T16:37:07.373Z","comments":true,"path":"api/articles/Rendering/主流AA算法及原理.json","keywords":null,"cover":"https://raw.githubusercontent.com/JBR-Bunjie/JBR-Bunjie/main/back.jpg","content":"<h1 id=\"主流-anti-aliasing-算法及原理概览\">主流 Anti-Aliasing\r\n算法及原理概览</h1>\r\n<blockquote>\r\n<p>https://zhuanlan.zhihu.com/p/57503957</p>\r\n</blockquote>\r\n<h2 id=\"spatial-anti-aliasing\">Spatial Anti-Aliasing</h2>\r\n<h3 id=\"ssaa\">SSAA</h3>\r\n<p>SSAA，即 Super sampling anti-aliasing，有时也称为 full-scene\r\nanti-aliasing (FSAA)，一般认为是性能消耗很大的一种抗锯齿方案。</p>\r\n<p>基本思路为：我们通过在更高的分辨率，使用更多的采样点来进行渲染，并在完成渲染后对结果进行混合以及下采样得到最终的结果</p>\r\n<blockquote>\r\n<p>Color samples are taken at several instances inside the pixel (not\r\njust at the center as normal), and an average color value is calculated.\r\nThis is achieved by rendering the image at a much higher resolution than\r\nthe one being displayed, then shrinking it to the desired size, using\r\nthe extra pixels for calculation. The result is a downsampled image with\r\nsmoother transitions from one line of pixels to another along the edges\r\nof objects. The number of samples determines the quality of the\r\noutput.</p>\r\n<p>https://en.wikipedia.org/wiki/Supersampling</p>\r\n</blockquote>\r\n<p>这里有一篇关于具体步骤的总结：https://zhuanlan.zhihu.com/p/484890144</p>\r\n<p>这个做法的核心思路就是面多加水水多加面：既然锯齿的直接原因是采样不足，那我就增加渲染过程中的采样，以得到更好的画面。但是\r\nSSAA\r\n的做法并不算好：这样做的计算量太大了——甚至是对显卡、显存、带宽全方位的压力。</p>\r\n<h3 id=\"msaa\">MSAA</h3>\r\n<p>一般认为，MSAA 是唯一一个被硬件支持、有硬件实现的 AA\r\n算法，曾经业界普遍采用的方案之一。不过在延迟管线逐渐兴起、众多 AA\r\n方案如雨后春笋般冒出的当下，MSAA 的一些局限性也开始暴露出来。</p>\r\n<blockquote>\r\n<p>Super sampling anti-aliasing (SSAA), also called full-scene\r\nanti-aliasing (FSAA), is used to avoid aliasing (or \"jaggies\") on\r\nfull-screen images. SSAA was the first type of anti-aliasing available\r\nwith early video cards. But due to its tremendous computational cost and\r\nthe advent of multisample anti-aliasing (MSAA) support on GPUs, it is no\r\nlonger widely used in real time applications. MSAA provides somewhat\r\nlower graphic quality, but also tremendous savings in computational\r\npower.</p>\r\n<p>https://en.wikipedia.org/wiki/Spatial_anti-aliasing</p>\r\n</blockquote>\r\n<p>对于 MSAA 的过程可作简述如下：我们保留 SSAA\r\n中的采样点，但我们将会提前——在光栅化阶段就进行覆盖判断。记录覆盖结果，并在之后的着色中，对存在通过判断的采样点的像素进行着色。分别对通过的采样点进行深度测试等，最后将通过这些测试的结果保存至对应缓冲的对应位置。在所有渲染工作完成时，我们会进行一步\"Resolve\"操作，它会合并所有的\r\nmulti-sampled textures 以得到最终结果。</p>\r\n<blockquote>\r\n<p>For DirectX, resolving a texture means blending multi-sampled texture\r\ninto a non-multisampled one. For simple scenarios this is usually done\r\nautomatically by the output merger, but is often needed to be done\r\nexplicitly (e.g. ResolveSubresource) when using multi-sampled render\r\ntarget as an input for a next render pass (e.g. post-processing).\r\nReasons being both performance and lower complexity of the following\r\npass shaders.</p>\r\n<p>https://computergraphics.stackexchange.com/questions/9262/what-does-texture-resolve-mean</p>\r\n</blockquote>\r\n<p>下图是 DX11 的光栅化说明文档中的 MSAA 示意图，非常详细地展示了 MSAA\r\n的应用原理。</p>\r\n<figure>\r\n<img src=\"....\\images\\Rendering\\image-20231006191532143.png\"\r\nalt=\"image-20231006191532143\" />\r\n<figcaption aria-hidden=\"true\">image-20231006191532143</figcaption>\r\n</figure>\r\n<blockquote>\r\n<p>关于 MSAA，可以参考：https://zhuanlan.zhihu.com/p/415087003</p>\r\n</blockquote>\r\n<p>从以上的内容中，你大概可以看出：相对于\r\nSSAA，我们降低了显卡的计算量——一个像素块仍然只需要一次计算就足够了，但显存和带宽上的压力仍在——因为采样点依然存在。重要的是，这些带宽并没有得到有效利用——很多带宽被浪费了——这也就是为什么延迟管线不会采用\r\nMSAA 的原因。</p>\r\n<h3 id=\"taa\">TAA</h3>\r\n<p>接着看 TAA，Temporal Anti-Aliasing</p>\r\n<blockquote>\r\n<p>https://zhuanlan.zhihu.com/p/57503885</p>\r\n</blockquote>\r\n<p>和 SSAA 类似的是，TAA 的每个像素点同样有多个\"采样点\"。但是不同与 SSAA\r\n的是，TAA\r\n会综合历史帧的数据来实现抗锯齿，这样会将每个像素点的多次采样成本均摊到多个帧中，相对的开销要小得多，同时，由于\r\nTAA\r\n是从前后帧来获取，将每个像素的多次采样分摊到多个帧中来实现的，其实际的执行效率相较于\r\nMSAA\r\n会高上不少。不过，既然是综合历史帧的算法，其效果必然会因为物体运动而收到影响。</p>\r\n<blockquote>\r\n<p>Sampling the pixels at a different position in each frame can be\r\nachieved by adding a per-frame \"jitter\" when rendering the frames. The\r\n\"jitter\" is a 2D offset that shifts the pixel grid, and its X and Y\r\nmagnitude are between 0 and 1.</p>\r\n<p>When combining pixels sampled in past frames with pixels sampled in\r\nthe current frame, care needs to be taken to avoid blending pixels that\r\ncontain different objects, which would produce ghosting or\r\nmotion-blurring artifacts. Different implementation of TAA have\r\ndifferent ways of achieving this. Possible methods include:</p>\r\n<p>Using motion vectors from the game engine to perform motion\r\ncompensation before blending. Limiting (clamping) the final value of a\r\npixel by the values of pixels surrounding it.</p>\r\n<p>https://en.wikipedia.org/wiki/Temporal_anti-aliasing</p>\r\n</blockquote>\r\n<p><img\r\nsrc=\"https://picx.zhimg.com/v2-7585c87dde80b1f19b908d8c74724cfc_720w.jpg?source=d16d100b\"\r\nalt=\"img\" /> 一种可用的采样点序列实例：Halton 采样序列</p>\r\n<p>TAA 的具体流程可参考：https://zhuanlan.zhihu.com/p/425233743</p>\r\n<h2 id=\"morphological-anti-aliasing\">Morphological Anti-Aliasing</h2>\r\n<p>除了增加采样点的数目，另一种常见的抗锯齿方案是通过后处理的方式来完成——例如\r\nFXAA 和 SMAA。</p>\r\n<p>它的思路也很简单：既然大多数锯齿都只出现在物体边缘或者高光变化的部分，那我们通过后处理的方式，检测出图像块之间的边缘，然后根据边缘信息对边缘两侧的图像进行混合处理，就可以达到抗锯齿的效果了。</p>\r\n<p>比如下图中的图像，左边是待处理的图像，中间是找到的边界，右侧是将边界两侧像素混合后得到的抗锯齿效果。</p>\r\n<figure>\r\n<img\r\nsrc=\"https://pic1.zhimg.com/v2-8f2778c2af4c2811a6017ea04e935ca4_720w.jpg?source=d16d100b\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<h3 id=\"fxaa\">FXAA</h3>\r\n<p>FXAA，即 Fast approximate anti-aliasing：</p>\r\n<blockquote>\r\n<p>Fast approximate anti-aliasing (FXAA) is a screen-space anti-aliasing\r\nalgorithm created by Timothy Lottes at Nvidia.</p>\r\n<p>FXAA 3 is released under a public domain license. A later version,\r\nFXAA 3.11, is released under a 3-clause BSD license.</p>\r\n<p>https://en.wikipedia.org/wiki/Fast_approximate_anti-aliasing</p>\r\n</blockquote>\r\n<p>FXAA3.11 有两个版本：注重抗锯齿质量的 Quality 版本和注重抗锯齿速度的\r\nConsole 版本。</p>\r\n<blockquote>\r\n<p>即使是 FXAA3.11，也已经是很有年头的东西了——这是出现于 2011 年，适用于\r\nGTX4 系的技术。</p>\r\n</blockquote>\r\n<p>FXAA 大致步骤如下：</p>\r\n<ol type=\"1\">\r\n<li><p>计算亮度与对比度：</p>\r\n<ol type=\"1\">\r\n<li><p>首先是求亮度，这可以使用常用的求亮度公式 L = 0.213 _ R + 0.715 _\r\nG + 0.072 * B，也可以直接使用 G\r\n分量的颜色值作为亮度值，因为绿色对整体亮度的贡献是最大的。当然，我们也可以直接从采样结果中获取——这需要我们提前将亮度保存在\r\nalpha 通道中</p></li>\r\n<li><p>采样亮度，计算对比度：</p>\r\n<p>采样的位置是下图所示的点，分别得到中间点 M 和周围四个点 N、E、W、S\r\n的亮度值。</p>\r\n<figure>\r\n<img\r\nsrc=\"https://pic4.zhimg.com/80/v2-f2feb0d89d8040408c8503362d0dd9e7_1440w.webp\"\r\nalt=\"img\" />\r\n<figcaption aria-hidden=\"true\">img</figcaption>\r\n</figure>\r\n<p>可以直接用最大亮度和最小亮度的差作为对比度：</p>\r\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">float MaxLuma &#x3D; max(N, E, W, S, M);\nfloat MinLuma &#x3D; min(N, E, W, S, M);\nfloat Contrast &#x3D;  MaxLuma - MinLuma;\nif(Contrast &gt;&#x3D; max(_MinThreshold, MaxLuma * _Threshold)) &#123;\n&#x2F;&#x2F;    ...\n&#125;</code></pre>\r\n<p>如果得到的对比度值比较小，可以认为当前的点，不需要进行锯齿处理。</p></li>\r\n</ol></li>\r\n<li><p>基于亮度的混合系数计算</p></li>\r\n</ol>\r\n<p>关于像素边缘采样：</p>\r\n<h3 id=\"smaa\">SMAA</h3>\r\n<h2 id=\"fsr\">FSR</h2>\r\n<blockquote>\r\n<p>https://zhuanlan.zhihu.com/p/532302889</p>\r\n</blockquote>\r\n<h2 id=\"tsr\">TSR</h2>\r\n<h2 id=\"deep-learning-anti-aliasing\">Deep Learning Anti-Aliasing</h2>\r\n<h3 id=\"dlss\">DLSS</h3>\r\n<h2 id=\"references\">References</h2>\r\n<ul>\r\n<li>https://zhuanlan.zhihu.com/p/57503957</li>\r\n</ul>\r\n","text":"主流 Anti-Aliasing 算法及原理概览 https://zhuanlan.zhihu.com/p/57503957 Spatial Anti-Aliasing SSAA SSAA，即 Super sampling anti-aliasing，有时也称为 full-sce...","link":"","photos":[],"count_time":{"symbolsCount":"5.2k","symbolsTime":"5 mins."},"categories":[{"name":"Algorithm","slug":"Algorithm","count":31,"path":"api/categories/Algorithm.json"},{"name":"Rendering","slug":"Algorithm/Rendering","count":1,"path":"api/categories/Algorithm/Rendering.json"},{"name":"AA","slug":"Algorithm/Rendering/AA","count":1,"path":"api/categories/Algorithm/Rendering/AA.json"}],"tags":[{"name":"Algorithm","slug":"Algorithm","count":31,"path":"api/tags/Algorithm.json"},{"name":"Rendering","slug":"Rendering","count":3,"path":"api/tags/Rendering.json"},{"name":"AA","slug":"AA","count":1,"path":"api/tags/AA.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%BB%E6%B5%81-anti-aliasing-%E7%AE%97%E6%B3%95%E5%8F%8A%E5%8E%9F%E7%90%86%E6%A6%82%E8%A7%88\"><span class=\"toc-text\">主流 Anti-Aliasing\r\n算法及原理概览</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#spatial-anti-aliasing\"><span class=\"toc-text\">Spatial Anti-Aliasing</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#ssaa\"><span class=\"toc-text\">SSAA</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#msaa\"><span class=\"toc-text\">MSAA</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#taa\"><span class=\"toc-text\">TAA</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#morphological-anti-aliasing\"><span class=\"toc-text\">Morphological Anti-Aliasing</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#fxaa\"><span class=\"toc-text\">FXAA</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#smaa\"><span class=\"toc-text\">SMAA</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#fsr\"><span class=\"toc-text\">FSR</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#tsr\"><span class=\"toc-text\">TSR</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#deep-learning-anti-aliasing\"><span class=\"toc-text\">Deep Learning Anti-Aliasing</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#dlss\"><span class=\"toc-text\">DLSS</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#references\"><span class=\"toc-text\">References</span></a></li></ol></li></ol>","author":{"name":"JBR_Bunjie","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/90251718?v=4","link":"/","description":"仿生程序员会在光环上遇见AI乐正绫吗？","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-fill.svg","link":"https://space.bilibili.com/415377461"},"github":{"icon":"/svg/social_github.svg","link":"https://github.com/JBR-Bunjie"}}}},"mapped":true,"prev_post":{"title":"实现一个视差体积雾吧！","uid":"71fbc7ff44065d31551c0ea05fc7175a","slug":"Rendering/ParallaxCloud","date":"2023-03-02T04:23:23.000Z","updated":"2023-10-27T20:20:43.000Z","comments":true,"path":"api/articles/Rendering/ParallaxCloud.json","keywords":null,"cover":"https://raw.githubusercontent.com/JBR-Bunjie/JBR-Bunjie/main/back.jpg","text":"实现一个视差体积雾吧！ 原理说明 核心思路：基于一张噪点图，基于切线空间下的视线方向，不断偏移 uv 来取样其中的内容，由于 Texture 下暗处的 rgb 三值都会急速下降并趋于 0，因此让 uv 偏移到暗处即可形成自然的颜色渐变——我们的视差体积雾即以该内容来伪装“高度”。...","link":"","photos":[],"count_time":{"symbolsCount":"4.9k","symbolsTime":"4 mins."},"categories":[{"name":"Unity","slug":"Unity","count":18,"path":"api/categories/Unity.json"},{"name":"Shader","slug":"Unity/Shader","count":7,"path":"api/categories/Unity/Shader.json"}],"tags":[{"name":"Unity","slug":"Unity","count":18,"path":"api/tags/Unity.json"},{"name":"Shader","slug":"Shader","count":33,"path":"api/tags/Shader.json"}],"author":{"name":"JBR_Bunjie","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/90251718?v=4","link":"/","description":"仿生程序员会在光环上遇见AI乐正绫吗？","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-fill.svg","link":"https://space.bilibili.com/415377461"},"github":{"icon":"/svg/social_github.svg","link":"https://github.com/JBR-Bunjie"}}}}},"next_post":{"title":"设计模式在游戏编程中的实践","uid":"d603f61c6dd6ebd8e3ed06a28bd85050","slug":"Dev/Theory/设计模式在游戏中的实践","date":"2023-02-02T04:23:23.000Z","updated":"2023-10-27T19:44:35.000Z","comments":true,"path":"api/articles/Dev/Theory/设计模式在游戏中的实践.json","keywords":null,"cover":"https://raw.githubusercontent.com/JBR-Bunjie/JBR-Bunjie/main/back.jpg","text":"设计模式在游戏编程中的实践 设计模式 命令模式 将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化； 对请求排队或记录请求日志，以及支持可撤销的操作。 命令模式至少包含这样几个部分： img 介绍 意图：将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参...","link":"","photos":[],"count_time":{"symbolsCount":"25k","symbolsTime":"23 mins."},"categories":[{"name":"Theroy","slug":"Theroy","count":5,"path":"api/categories/Theroy.json"}],"tags":[{"name":"Theroy","slug":"Theroy","count":5,"path":"api/tags/Theroy.json"}],"author":{"name":"JBR_Bunjie","slug":"blog-author","avatar":"https://avatars.githubusercontent.com/u/90251718?v=4","link":"/","description":"仿生程序员会在光环上遇见AI乐正绫吗？","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-fill.svg","link":"https://space.bilibili.com/415377461"},"github":{"icon":"/svg/social_github.svg","link":"https://github.com/JBR-Bunjie"}}}}}}